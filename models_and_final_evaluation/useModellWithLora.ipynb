{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeed387-579f-4082-af57-cf78eaa3b271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mit diesem Notebook kann ein gegebener LoRA Adapter verwendet werden, um auf Eingabefragen zu antworten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c26835ad-8ee1-4636-bdd5-047afe3f8aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart Kernel or jsut use the third cell after the first usage of the second cell\n",
    "lora_path = \"../pretraining/chatGptLorasPretraining/checkpoint-3451\" # e.g. \"../fullRun/lorasGptDataRun/checkpoint-862\"\n",
    "output_token_length = 400\n",
    "question = \"Sind „Bürgerliches Recht“, „Zivilrecht“ und „Privatrecht“ dasselbe oder gibt es Unterschiede?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f350ab5e-37b8-4732-afd8-9c1c50cae78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/ps2024/.cache/huggingface/token\n",
      "Login successful\n",
      "==((====))==  Unsloth 2024.9.post4: Fast Mistral patching. Transformers = 4.45.1.\n",
      "   \\\\   /|    GPU: Quadro RTX 6000. Max memory: 23.462 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.1. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Loaded -> reinforcement_gpt_862\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from huggingface_hub import login, logout\n",
    "from unsloth import FastLanguageModel\n",
    "import os\n",
    "from peft import PeftModel\n",
    "\n",
    "login(\"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\")\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# Gute Daten vom bisher best-trainierten Model\n",
    "base_model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/mistral-7b-v0.3\", \n",
    "    local_files_only = True, \n",
    "    max_seq_length = 400, # Choose any! We auto support RoPE Scaling internally!\n",
    "    dtype = None, # None for auto detection. Float16 \"or Tesla T4, V100, Bfloat16 for Ampere+\n",
    "    load_in_4bit = True, # Use 4bit quantization to reduce memory usage. Can be False.\n",
    ")\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(base_model, lora_path, is_trainable=False)\n",
    "print(\"Loaded -> \" + lora_path)\n",
    "\n",
    "FastLanguageModel.for_inference(base_model)\n",
    "\n",
    "input_ids = tokenizer(question, return_tensors=\"pt\").input_ids\n",
    "peft_model_outputs = peft_model.generate(input_ids=input_ids, repetition_penalty=1.4, early_stopping=True, max_new_tokens=output_token_length) # top_k=5, top_p=0.9, temperature=0.1,\n",
    "cut_tensor = peft_model_outputs[:, input_ids.size(1):]\n",
    "peft_model_text_output = tokenizer.decode(cut_tensor[0], skip_special_tokens=True, add_generation_prompt = False)\n",
    "print(peft_model_text_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5790bf77-8dae-4ca4-a730-859655ab5b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Die Angeklagten wurden wegen versuchten besonders schweren Betruges verurteilt. Die Staatsanwaltschaft legt Revision ein, da die Feststellungen des Landgerichts Braunschweig nicht tragen können und rechtliche Bedenken bestehen. Es wird argumentiert, dass kein Vermögensschaden bei den Kreditinstituten eingetreten sei, da ihre Bonusregelung nur auf das eigene Risikokapital abzielte und den Gesamtbestand nicht gefährdete. Zudem werden Rechtsfehler in der Bewertung von Täuschungsnachweisen und im Strafausspruch gesehen. Das Gericht hob das Urteil teilweise auf und verwies es zur neuen Verhandlung an eine andere Wirtschaftskammer zurück.\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(question, return_tensors=\"pt\").input_ids\n",
    "peft_model_outputs = peft_model.generate(input_ids=input_ids, repetition_penalty=1.4, early_stopping=True, max_new_tokens=output_token_length) # top_k=5, top_p=0.9, temperature=0.1,\n",
    "cut_tensor = peft_model_outputs[:, input_ids.size(1):]\n",
    "peft_model_text_output = tokenizer.decode(cut_tensor[0], skip_special_tokens=True, add_generation_prompt = False)\n",
    "print(peft_model_text_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68f0b97-22c7-4fdb-99c8-0b5f0839ecfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
